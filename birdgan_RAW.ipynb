{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#we have whitecrown sparrow and american robin samples\n",
    "\n",
    "class_ids = {\n",
    "    'sparrow': 0,\n",
    "    'robin': 1,\n",
    "}\n",
    "\n",
    "\n",
    "robin = wave.open('./recordings/ml-american-robin.wav', 'r')\n",
    "frame_n = robin.getnframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find silent frames of file\n",
    "#\n",
    "# @arg w sound wave file\n",
    "# @arg threshold threshold value for sound intensity\n",
    "#\n",
    "# @return s_frame_val all silent frames\n",
    "# @return frame_val all significant frames\n",
    "# @sig_frames number of sig frames\n",
    "# @frames total number of frames\n",
    "\n",
    "def silent_frames(w,threshold, x=0, y=-1, verbose=True):\n",
    "   \n",
    "    #init frame arrayws\n",
    "    init_size = w.getnframes()\n",
    "    \n",
    "    frames = np.empty(init_size)\n",
    "    s_frames = np.empty(init_size)\n",
    "    \n",
    "    frames_n=0\n",
    "    s_frames_n = 0\n",
    "    \n",
    "    if y == -1:\n",
    "        y = init_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(w.getnframes()):\n",
    "        # read a single frame and advance to next frame\n",
    "        current_frame= w.readframes(1)\n",
    "        \n",
    "        if w.tell() >= x:\n",
    "            #print(w.tell())\n",
    "\n",
    "            # check for silence\n",
    "            silent = True\n",
    "            # wave frame samples are stored in little endian**\n",
    "            # this example works for a single channel 16-bit per sample encoding\n",
    "            unpacked_signed_value = struct.unpack(\"<h\", current_frame) # *\n",
    "            if abs(unpacked_signed_value[0]) > threshold:\n",
    "                silent = False\n",
    "\n",
    "            if silent:\n",
    "                s_frames[s_frames_n] = w.tell()\n",
    "                s_frames_n +=1\n",
    "                if verbose:\n",
    "                    print (\"Frame %s is silent.\" % w.tell())\n",
    "                    print (\"silence found at second %s\" % (w.tell()/w.getframerate()))\n",
    "            else:\n",
    "                frames[frames_n] = w.tell()\n",
    "                frames_n +=1\n",
    "                if verbose:\n",
    "                    print (\"Frame %s is not silent.\" % w.tell())\n",
    "                \n",
    "            if w.tell() == y:\n",
    "                break\n",
    "\n",
    "    frames = np.resize(frames,frames_n)\n",
    "    s_frames = np.resize(s_frames,s_frames_n)\n",
    "    \n",
    "    \n",
    "    print(frames_n)            \n",
    "    return frames, s_frames        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2536701\n"
     ]
    }
   ],
   "source": [
    "frames, s_frames = silent_frames(robin, 50, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2003 pixels on png == 44100 frames on audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.692000e+03 1.693000e+03 1.694000e+03 ... 4.704835e+06 4.705076e+06\n",
      " 4.705077e+06]\n",
      "[1.000000e+00 2.000000e+00 3.000000e+00 ... 4.726654e+06 4.726655e+06\n",
      " 4.726656e+06]\n"
     ]
    }
   ],
   "source": [
    "print(frames[::])\n",
    "print(s_frames[::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2536701\n",
      "2189955\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))\n",
    "print(len(s_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silent_frames[::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(silent_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_pixel(f):\n",
    "    return f * 2003 / 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[frame_to_pixel(x) for x in[220000, 244200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find silent frames of file\n",
    "#\n",
    "# @arg w sound wave file\n",
    "# @arg frames list of heard frames\n",
    "# @arg stride how far the window moves each iter\n",
    "# @arg tol ratio of heard/silent calls considered acceptable\n",
    "#\n",
    "# @return ranges 2d numpy array containing list of ranges\n",
    "\n",
    "\n",
    "def find_audio(w, frames, window_size=150, stride=1, tol=0.3):\n",
    "    left_f = 0\n",
    "    right_f = window_size\n",
    "    \n",
    "    frame_end = int(frames[len(frames)-1])\n",
    "    \n",
    "    r_index = 0\n",
    "    l_index = 0\n",
    "    \n",
    "    #values to return for range\n",
    "    left = -1\n",
    "    right = -1\n",
    "    \n",
    "    ranges = np.zeros((w.getnframes()), dtype=(float,2))\n",
    "    \n",
    "    #get inital heard values\n",
    "    heard = 0\n",
    "    \n",
    "    for f in frames:\n",
    "            #outside window range set new values\n",
    "            if f >= right_f:\n",
    "                #set next window  ind \n",
    "                left_f += 1\n",
    "                right_f = left_f + window_size\n",
    "                \n",
    "                #set index in frames\n",
    "                r_index = heard\n",
    "                l_index += 1\n",
    "                \n",
    "                break\n",
    "            #increment heard frames\n",
    "            heard += 1\n",
    "            \n",
    "    #ratio of heard to window size\n",
    "    ratio = heard/window_size\n",
    "    \n",
    "    #if tol is high set left range\n",
    "    if ratio >= tol:\n",
    "        left = left_f\n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    while(right_f < frame_end):\n",
    "        #check if left value in frame range\n",
    "        if frames[l_index] <= left_f:\n",
    "            l_index += 1\n",
    "            heard -= 1\n",
    "            #print('left out of range')\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "        #check if right value in frame range\n",
    "        if frames[r_index] <= right_f:\n",
    "            r_index += 1\n",
    "            heard += 1\n",
    "            #print('right in range')\n",
    "            \n",
    "           #check if r_index is at edge\n",
    "        if(r_index >= frame_end-1):\n",
    "            ranges[i]=[left_f,right_f]\n",
    "            i+=1\n",
    "            break   \n",
    "            \n",
    "            \n",
    "            \n",
    "        #print(ratio)\n",
    "            \n",
    "        ratio = heard/window_size\n",
    "        \n",
    "        if ratio >= tol and left == -1:\n",
    "            left = left_f\n",
    "            \n",
    "        #print(ratio , '' , tol)\n",
    "\n",
    "        \n",
    "            \n",
    "        if ratio < tol and left != -1:\n",
    "            right = right_f\n",
    "            ranges[i] = [left_f,right_f]\n",
    "            i +=1\n",
    "            left = -1\n",
    "        \n",
    "        right_f += 1\n",
    "        left_f += 1\n",
    "        \n",
    "    ranges = np.resize(ranges,(i,2))        \n",
    "   \n",
    "    return ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.703000e+03, 1.853000e+03],\n",
       "       [1.922000e+03, 2.072000e+03],\n",
       "       [1.941000e+03, 2.091000e+03],\n",
       "       ...,\n",
       "       [4.704289e+06, 4.704439e+06],\n",
       "       [4.704565e+06, 4.704715e+06],\n",
       "       [4.704760e+06, 4.704910e+06]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = find_audio(robin,frames, tol = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4455"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
